# -*- coding: utf-8 -*-
"""Running UHRED model for the mineral sample 2021-02-19.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://drive.google.com/drive/folders/1Wnd8kgCrDWru8J4eJ5LBkvHkYA_veaMz?usp=sharing
"""

#Importing Libraries 
import os
from os import path
import numpy as np
import pandas as pd
from PIL import Image

import torch
import torch.nn as nn
#from scipy import ndimage 
from scipy.interpolate import interp1d
#from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator
from mpl_toolkits.axes_grid1 import make_axes_locatable
import plotly.graph_objs as go

#from improved_auto_encoderdecoder import Autoencoder
from auto_encoderdecoder import Autoencoder

torch.cuda.empty_cache()

#Read_tiff(path) can read the hyperspectral image cube and return it to a numpy array.
def read_tiff(path) :
    img = Image.open(path)
    images = []
    for i in range (img.n_frames) : 
        img.seek(i)
        images.append(np.array(img))
    return np.array(images)

# Resample spectra to a target_len
def resample_spectra(data, original_start, original_end, target_len):
    """
    Resample the spectra in the data cube to a new length while preserving the spectral range.
    
    Parameters:
    - data: numpy.ndarray
        Input data cube with shape [dim_x, dim_y, spectrum_len].
    - original_start: float
        Starting value of the original spectrum.
    - original_end: float
        Ending value of the original spectrum.
    - target_len: int
        Desired length of the resampled spectrum.
    
    Returns:
    - numpy.ndarray
        Resampled data cube with shape [dim_x, dim_y, target_len].
    """
    dim_x, dim_y, spec_len = data.shape
    
    # Original spectral axis
    x_old = np.linspace(original_start, original_end, spec_len)
    
    # New spectral axis (same start and end but with target_len points)
    x_new = np.linspace(original_start, original_end, target_len)
    
    # Initialize the output array
    resampled_data = np.zeros((dim_x, dim_y, target_len))
    
    # Iterate over each pixel and resample the spectrum
    for i in range(dim_x):
        for j in range(dim_y):
            spectrum = data[i, j, :]
            
            # Create interpolation function (linear interpolation by default)
            interpolator = interp1d(x_old, spectrum, 
                                    kind='linear', bounds_error=False, 
                                    fill_value='extrapolate')
            
            # Interpolate to new spectral axis
            resampled_spectrum = interpolator(x_new)          
            resampled_data[i, j, :] = resampled_spectrum
    
    return resampled_data

imgStk = read_tiff("./HSI_400-1000nm/WHU-Hi-LongKou.tif") 
#printing shape of the imgData
nframes, dim_x, dim_y = imgStk.shape
print (f"Shap of imgStk: {nframes} x {dim_x} x {dim_y}")

#Finding min, max and mean value of the imported data
mean_input = np.mean(imgStk)
max_input = np.max(imgStk)
min_input = np.min(imgStk)
differenc = max_input - min_input
print("Input data statistical features:\n")
print("//////////////////////////////////////")
print('\tMean value is = %f \n \tMax value is = %f \n \t Min value is = %f \n \tDifference of max and min value is = %f ' % (mean_input,max_input,min_input, differenc))

#Normalizing input data
imgStk = (imgStk - mean_input) / (max_input - min_input)
#Check the data normalization
print(" ")
print("Check the data normalization result")
print('\tMean value is = %f \n \tMax value is = %f \n \t Min value is = %f \n \tDifference of max and min value is = %f ' 
      % (np.mean(imgStk),np.max(imgStk),np.min(imgStk), np.max(imgStk) - np.min(imgStk)))

# Resample spectra with a target_len
original_start = 400.0   # e.g., 400 nm
original_end = 1000.0 
target_len = 500 # new spec_len

inpt = np.transpose(imgStk, (1, 2, 0))
resampled_data = resample_spectra(inpt, original_start, original_end, target_len)
resampled_data = resampled_data.astype(np.float32)  # Ensure the resampled data is in float32 format
print(f"Shape of Resampled data: {resampled_data.shape} (dim_x, dim_y, target_len)")
input = resampled_data
del imgStk, inpt, resampled_data

# Find the max voxel index [xp_index, yp_index, zp_index]
# 1. Find the slice index at the max spectral peak 
slice_sums = np.sum(input, axis=(0, 1))
# Find the index of the maximum sum
posz = np.argmax(slice_sums)
# Get the actual maximum sum value
zp = slice_sums[posz]
print(f"The max slice sum is {zp}, which occurs at layer {posz}")

# 2. Find the y-pixel index at the max x-line sum
slice = input[:, :, posz]
x_sums = np.sum(slice, axis=0)
# Find the index of the maximum sum
posy = np.argmax(x_sums)
# Get the actual maximum sum value
yp = x_sums[posy]
print(f"The max x-line sum is {yp}, which occurs at y-pixel {posy}")

# 3. Find the x-pixel index at the max y-line sum
y_sums = np.sum(slice, axis=1)
# Find the index of the maximum sum
posx = np.argmax(y_sums)
# Get the actual maximum sum value
xp = x_sums[posx]
print(f"The max y-line sum is {xp}, which occurs at x-pixel {posx}")

# Ploting the slice images of the input data cube
fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10, 10))

im1 = ax1.imshow(input[:,:,1],cmap='RdBu')
divider = make_axes_locatable(ax1)
cax = divider.append_axes("right", size="5%", pad=0.05)
fig.colorbar(im1, cax=cax, orientation='vertical')

im2 = ax2.imshow(input[:,:,posz],cmap='RdBu')
divider = make_axes_locatable(ax2)
cax = divider.append_axes("right", size="5%", pad=0.05)
fig.colorbar(im2, cax=cax, orientation='vertical')

ax1.set_title('Bkg: data at spec-channel 1', fontsize = 16)
ax2.set_title(f'Input data at spec-channel {posz}', fontsize = 16)
ax2.set_axis_off()
ax1.set_axis_off()

# Reshape it to img1d = dim_x*dim_y and then covert it to torch tensor. 
dim_x, dim_y, dim_z = input.shape

img1d = dim_x*dim_y
input_t = input.reshape((img1d,-1))

input_t = torch.from_numpy(input_t).float()
input_t = input_t.view(-1,1,dim_z)
print(f"Shape of input_t = {input_t.shape}")

#Output of the NN
outpt = torch.zeros([img1d,1,dim_z],dtype=torch.float)

#loading the model parameters
model = Autoencoder(zdims=32, n_frames=dim_z)
model_save_name = 'uhred_minerals.pt'
path = F"./model/{model_save_name}"
model.load_state_dict(torch.load(path, map_location='cpu'))

# For classifiction the technic that we are going to use is taking advantage of Latent space. 
# This requires to feed in all input data to just Encoder layer and then by applying one of 
# clustering method like k_mean labeling every single pixel.
# projecting input data to latent space for the purpose of classification. 

model.eval() # Set model to evaluation mode
with torch.no_grad():
    outpt = model(input_t)
    print(f"Shape of model output: {outpt.shape}")

# Reshape the outpt Torch tensor, and make it an image format.
outpt = outpt.view(img1d, dim_z)
outpt = outpt.detach().cpu().numpy()
outpt = outpt.reshape(dim_x,dim_y,-1)
print(f"Shape of outpt = {outpt.shape}")

# Display the statistics of outpt tensor 
max_outpt = np.max(outpt)
min_outpt = np.min(outpt)
mean_outpt = np.mean(outpt)

print("Output data statistical features:")
print("//////////////////////////////////////\n")
print ('\tmean = %f \n \tmax = %f \n \tmin = %f ' % (mean_outpt,max_outpt,min_outpt))
print('\tVariance of the Output data:',max_outpt-min_outpt)

"""Compare the AE model output with the input image data."""
# plot a spectral-peak (posz) frame of the input data cube
fig,(ax1,ax2) = plt.subplots(1,2,figsize=(8, 8))

im1 = ax1.imshow(input[:,:,posz],cmap='RdBu', vmin=-0.4, vmax=0.4)
divider = make_axes_locatable(ax1)
cax = divider.append_axes("right", size="5%", pad=0.08)
fig.colorbar(im1, cax=cax, orientation='vertical')

im2 = ax2.imshow(outpt[:,:,posz], cmap='RdBu', vmin=-0.3, vmax=0.3)
divider = make_axes_locatable(ax2)
cax = divider.append_axes("right", size="5%", pad=0.08)
fig.colorbar(im2, cax=cax, orientation='vertical')

ax1.set_title(f'Input @ sp={posz}', fontsize = 12)
ax2.set_title(f'AED Output @ sp={posz}', fontsize = 12)
ax2.set_axis_off()
ax1.set_axis_off()

plt.show()

"""Checking spectral reconstruction. Every single pixel contains full spectrum information. """
"""Defining x axis. which represents the Raman shift."""
# x represents Raman shift.
x = np.linspace(original_start,original_end,dim_z)

# Ploting a single pixel spectrum of the reconstructed data.
plt.figure(figsize=(8, 6))
plt.plot(x, outpt[posx,posy,:],color = 'r',alpha=0.8,linewidth=2,label='AED-output')

# Ploting a single-pixel spectrum of the input data on top of each other
plt.plot(x, input[posx,posy,:],color = 'g',alpha=0.6,label='Input')
plt.tick_params(width = 2,length = 4,direction = "in")
plt.legend(prop={'size': 12},shadow=True, bbox_to_anchor=(0.5, 0.8))
plt.xticks(fontsize=14)
y_ticks = np.arange(-0.2, 1.1, 0.4)
plt.yticks(y_ticks,fontsize = 12)
plt.ylabel('Normalized Intensity',fontsize = 14)
plt.xlabel('Raman Shift (cm^-1)', fontsize = 14)
plt.title(f'Spectrum at Pixel ({posx},{posy})', fontsize = 14)
plt.show()

model.eval() # Set model to evaluation mode
with torch.no_grad():
    # We only need the latent vector 'z' for clustering
    latent_space, _ = model.encode(input_t) 
    latent_space = latent_space.cpu().numpy()
    # checking latent space shape.
    print(f"Shape of latent space = {latent_space.shape}")

# 1. Scale the Data (Good Practice)
scaler = StandardScaler()
latent_space_scaled = scaler.fit_transform(latent_space)
del latent_space

# 2. Perform Clustering with GMM
n_clusters = 5
gmm = GaussianMixture(n_components=n_clusters, random_state=42)
clusters = gmm.fit_predict(latent_space_scaled)

# Get cluster counts:
cluster_counts = np.bincount(clusters)
print(f"Data points per cluster: {cluster_counts}")

# 3. Get Cluster Gravity Centers (Means)
# These are the "gravity centers" of the Gaussian components
cluster_centers_scaled = gmm.means_

# 4. Inverse-transform the centers back to the original latent space scale
cluster_centers_original = scaler.inverse_transform(cluster_centers_scaled)

# 5. Decode the Representative Spectra from the Centers
with torch.no_grad():
    # Convert centers to a tensor and move to the model's device
    centers_tensor = torch.from_numpy(cluster_centers_original).float()
    
    # Use the modified decode method (input_sizes is not needed)
    representative_spectra = model.decode(centers_tensor)
    representative_spectra = representative_spectra.cpu().numpy()

# 6. Plot the Representative Spectra
fig, axs = plt.subplots(n_clusters, 1, constrained_layout=True)

# Plot each graph, and manually set the y tick values
for i in range(n_clusters):
    axs[i].plot(x, representative_spectra[i].squeeze(), label=f'Cluster {i+1} Center')
    plt.legend(fontsize=10)
    axs[i].set_xlim(np.min(x), np.max(x))

plt.xlabel('Raman Shift (cm^-1)', fontsize=12)
plt.show()

#Compare the segmented image with input image
#Panda converted to Numpy array, every single pixel is color coded.
latent_space = pd.DataFrame(latent_space_scaled)
latent_space["Clusters"] = clusters
Latet_cluster_img = latent_space["Clusters"].to_numpy()
Latet_cluster_img = np.reshape(Latet_cluster_img,(dim_x,dim_y))
print("Shape of the color coded image is:", Latet_cluster_img.shape)

from matplotlib.colors import ListedColormap
fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10, 10))
cmap = ListedColormap(["gray", "green","blue","orange","red"])
im1 = ax1.imshow(Latet_cluster_img, cmap = cmap)
divider = make_axes_locatable(ax1)
cax = divider.append_axes("right", size="5%", pad=0.05)
fig.colorbar(im1, cax=cax, orientation='vertical')

im2 = ax2.imshow(input[:,:,posz],cmap='RdBu', vmin=-0.4, vmax=0.4)
divider = make_axes_locatable(ax2)
cax = divider.append_axes("right", size="5%", pad=0.05)
fig.colorbar(im2, cax=cax, orientation='vertical')

ax1.set_title('Image of 5 Kmean Clusters', fontsize = 16)
ax2.set_title(f'Model Output @ sp={posz}', fontsize = 16)
ax2.set_axis_off()
ax1.set_axis_off()

plt.show()
